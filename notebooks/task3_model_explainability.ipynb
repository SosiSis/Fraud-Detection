{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Model Explainability\n",
    "## Advanced Fraud Detection System\n",
    "\n",
    "This notebook covers model explainability using SHAP and LIME for understanding fraud detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model explainability libraries\n",
    "import shap\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Initialize SHAP\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed datasets\n",
    "print(\"Loading datasets and models...\")\n",
    "\n",
    "try:\n",
    "    # Load processed data\n",
    "    fraud_data = pd.read_csv('../data/fraud_data_processed.csv')\n",
    "    credit_data = pd.read_csv('../data/credit_card_processed.csv')\n",
    "    print(f\"Fraud data shape: {fraud_data.shape}\")\n",
    "    print(f\"Credit data shape: {credit_data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Processed data not found. Loading original data...\")\n",
    "    fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "    credit_data = pd.read_csv('../data/creditcard.csv')\n",
    "    \n",
    "    # Basic preprocessing for original data\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # Process fraud data\n",
    "    fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "    fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "    fraud_data['hour_of_day'] = fraud_data['purchase_time'].dt.hour\n",
    "    fraud_data['day_of_week'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    for col in ['source', 'browser', 'sex']:\n",
    "        fraud_data[f'{col}_encoded'] = le.fit_transform(fraud_data[col])\n",
    "    \n",
    "    # Select relevant features\n",
    "    fraud_features = ['purchase_value', 'age', 'hour_of_day', 'day_of_week', \n",
    "                     'source_encoded', 'browser_encoded', 'sex_encoded']\n",
    "    fraud_data = fraud_data[fraud_features + ['class']]\n",
    "\n",
    "print(\"Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for explainability\n",
    "print(\"=== DATA PREPARATION ===\")\n",
    "\n",
    "# Fraud data preparation\n",
    "if 'class' in fraud_data.columns:\n",
    "    X_fraud = fraud_data.drop(columns=['class'])\n",
    "    y_fraud = fraud_data['class']\n",
    "else:\n",
    "    print(\"Error: 'class' column not found in fraud data\")\n",
    "\n",
    "# Credit data preparation\n",
    "if 'Class' in credit_data.columns:\n",
    "    X_credit = credit_data.drop(columns=['Class'])\n",
    "    y_credit = credit_data['Class']\n",
    "else:\n",
    "    print(\"Error: 'Class' column not found in credit data\")\n",
    "\n",
    "# Train-test split\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(\n",
    "    X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud\n",
    ")\n",
    "\n",
    "X_credit_train, X_credit_test, y_credit_train, y_credit_test = train_test_split(\n",
    "    X_credit, y_credit, test_size=0.2, random_state=42, stratify=y_credit\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler_fraud = StandardScaler()\n",
    "scaler_credit = StandardScaler()\n",
    "\n",
    "X_fraud_train_scaled = scaler_fraud.fit_transform(X_fraud_train)\n",
    "X_fraud_test_scaled = scaler_fraud.transform(X_fraud_test)\n",
    "\n",
    "X_credit_train_scaled = scaler_credit.fit_transform(X_credit_train)\n",
    "X_credit_test_scaled = scaler_credit.transform(X_credit_test)\n",
    "\n",
    "print(f\"Fraud training set: {X_fraud_train_scaled.shape}\")\n",
    "print(f\"Credit training set: {X_credit_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models for explainability (if not already available)\n",
    "print(\"=== MODEL TRAINING FOR EXPLAINABILITY ===\")\n",
    "\n",
    "# Try to load pre-trained models\n",
    "try:\n",
    "    fraud_model = joblib.load('../models/best_fraud_model.pkl')\n",
    "    credit_model = joblib.load('../models/best_credit_model.pkl')\n",
    "    print(\"Loaded pre-trained models successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Pre-trained models not found. Training new models...\")\n",
    "    \n",
    "    # Train Random Forest models for explainability\n",
    "    fraud_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    credit_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    fraud_model.fit(X_fraud_train_scaled, y_fraud_train)\n",
    "    credit_model.fit(X_credit_train_scaled, y_credit_train)\n",
    "    \n",
    "    # Evaluate models\n",
    "    fraud_pred = fraud_model.predict(X_fraud_test_scaled)\n",
    "    credit_pred = credit_model.predict(X_credit_test_scaled)\n",
    "    \n",
    "    print(f\"Fraud model accuracy: {accuracy_score(y_fraud_test, fraud_pred):.4f}\")\n",
    "    print(f\"Credit model accuracy: {accuracy_score(y_credit_test, credit_pred):.4f}\")\n",
    "\n",
    "# Also train Logistic Regression for comparison\n",
    "fraud_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "credit_lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "fraud_lr.fit(X_fraud_train_scaled, y_fraud_train)\n",
    "credit_lr.fit(X_credit_train_scaled, y_credit_train)\n",
    "\n",
    "print(\"Models prepared for explainability analysis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SHAP Explainability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Analysis for Fraud Detection Model\n",
    "print(\"=== SHAP ANALYSIS - FRAUD MODEL ===\")\n",
    "\n",
    "# Create SHAP explainer for Random Forest\n",
    "fraud_explainer = shap.TreeExplainer(fraud_model)\n",
    "\n",
    "# Calculate SHAP values for test set (sample for performance)\n",
    "sample_size = min(1000, len(X_fraud_test_scaled))\n",
    "sample_indices = np.random.choice(len(X_fraud_test_scaled), sample_size, replace=False)\n",
    "X_fraud_sample = X_fraud_test_scaled[sample_indices]\n",
    "y_fraud_sample = y_fraud_test.iloc[sample_indices]\n",
    "\n",
    "fraud_shap_values = fraud_explainer.shap_values(X_fraud_sample)\n",
    "\n",
    "print(f\"SHAP values calculated for {sample_size} fraud samples\")\n",
    "print(f\"SHAP values shape: {fraud_shap_values[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot for Fraud Model\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(fraud_shap_values[1], X_fraud_sample, feature_names=X_fraud.columns, show=False)\n",
    "plt.title('SHAP Summary Plot - Fraud Detection Model')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"SHAP Summary Plot shows:\")\n",
    "print(\"- Feature importance (x-axis)\")\n",
    "print(\"- Feature values (color: red=high, blue=low)\")\n",
    "print(\"- Impact on model output (positive/negative SHAP values)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Feature Importance Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(fraud_shap_values[1], X_fraud_sample, feature_names=X_fraud.columns, \n",
    "                  plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance - Fraud Detection Model')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate mean absolute SHAP values for feature importance\n",
    "fraud_feature_importance = np.abs(fraud_shap_values[1]).mean(axis=0)\n",
    "fraud_importance_df = pd.DataFrame({\n",
    "    'feature': X_fraud.columns,\n",
    "    'importance': fraud_feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features (Fraud Model):\")\n",
    "print(fraud_importance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Dependence Plots for top features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "top_features = fraud_importance_df.head(4)['feature'].tolist()\n",
    "\n",
    "for i, feature in enumerate(top_features):\n",
    "    feature_idx = list(X_fraud.columns).index(feature)\n",
    "    plt.sca(axes[i])\n",
    "    shap.dependence_plot(feature_idx, fraud_shap_values[1], X_fraud_sample, \n",
    "                        feature_names=X_fraud.columns, show=False)\n",
    "    plt.title(f'SHAP Dependence Plot - {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Dependence plots show how feature values affect SHAP values (model output)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Analysis for Credit Card Model\n",
    "print(\"=== SHAP ANALYSIS - CREDIT CARD MODEL ===\")\n",
    "\n",
    "# Create SHAP explainer for Credit Card model\n",
    "credit_explainer = shap.TreeExplainer(credit_model)\n",
    "\n",
    "# Calculate SHAP values for test set (sample for performance)\n",
    "sample_size = min(1000, len(X_credit_test_scaled))\n",
    "sample_indices = np.random.choice(len(X_credit_test_scaled), sample_size, replace=False)\n",
    "X_credit_sample = X_credit_test_scaled[sample_indices]\n",
    "y_credit_sample = y_credit_test.iloc[sample_indices]\n",
    "\n",
    "credit_shap_values = credit_explainer.shap_values(X_credit_sample)\n",
    "\n",
    "print(f\"SHAP values calculated for {sample_size} credit samples\")\n",
    "print(f\"SHAP values shape: {credit_shap_values[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Summary Plot for Credit Card Model\n",
    "plt.figure(figsize=(12, 10))\n",
    "# Select top 15 features for better visualization\n",
    "credit_feature_importance = np.abs(credit_shap_values[1]).mean(axis=0)\n",
    "top_15_indices = np.argsort(credit_feature_importance)[-15:]\n",
    "\n",
    "shap.summary_plot(credit_shap_values[1][:, top_15_indices], \n",
    "                  X_credit_sample[:, top_15_indices], \n",
    "                  feature_names=[X_credit.columns[i] for i in top_15_indices], \n",
    "                  show=False)\n",
    "plt.title('SHAP Summary Plot - Credit Card Fraud Model (Top 15 Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Feature Importance for Credit Model\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(credit_shap_values[1][:, top_15_indices], \n",
    "                  X_credit_sample[:, top_15_indices], \n",
    "                  feature_names=[X_credit.columns[i] for i in top_15_indices],\n",
    "                  plot_type=\"bar\", show=False)\n",
    "plt.title('SHAP Feature Importance - Credit Card Fraud Model (Top 15 Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create importance dataframe\n",
    "credit_importance_df = pd.DataFrame({\n",
    "    'feature': X_credit.columns,\n",
    "    'importance': credit_feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features (Credit Card Model):\")\n",
    "print(credit_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP Force Plot for Individual Predictions\n",
    "print(\"=== SHAP FORCE PLOTS FOR INDIVIDUAL PREDICTIONS ===\")\n",
    "\n",
    "# Find fraud and non-fraud examples\n",
    "fraud_indices = np.where(y_fraud_sample == 1)[0]\n",
    "non_fraud_indices = np.where(y_fraud_sample == 0)[0]\n",
    "\n",
    "if len(fraud_indices) > 0 and len(non_fraud_indices) > 0:\n",
    "    # Force plot for a fraud case\n",
    "    fraud_idx = fraud_indices[0]\n",
    "    print(f\"\\nForce plot for FRAUD case (index {fraud_idx}):\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    shap.force_plot(fraud_explainer.expected_value[1], \n",
    "                   fraud_shap_values[1][fraud_idx], \n",
    "                   X_fraud_sample[fraud_idx], \n",
    "                   feature_names=X_fraud.columns,\n",
    "                   matplotlib=True, show=False)\n",
    "    plt.title('SHAP Force Plot - Fraud Case')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Force plot for a non-fraud case\n",
    "    non_fraud_idx = non_fraud_indices[0]\n",
    "    print(f\"\\nForce plot for NON-FRAUD case (index {non_fraud_idx}):\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    shap.force_plot(fraud_explainer.expected_value[1], \n",
    "                   fraud_shap_values[1][non_fraud_idx], \n",
    "                   X_fraud_sample[non_fraud_idx], \n",
    "                   feature_names=X_fraud.columns,\n",
    "                   matplotlib=True, show=False)\n",
    "    plt.title('SHAP Force Plot - Non-Fraud Case')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Force plots show:\")\n",
    "    print(\"- Base value (expected model output)\")\n",
    "    print(\"- Features pushing prediction higher (red) or lower (blue)\")\n",
    "    print(\"- Final prediction value\")\n",
    "else:\n",
    "    print(\"Not enough fraud/non-fraud cases in sample for force plots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LIME Explainability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME Analysis for Fraud Detection Model\n",
    "print(\"=== LIME ANALYSIS - FRAUD MODEL ===\")\n",
    "\n",
    "# Create LIME explainer\n",
    "fraud_lime_explainer = LimeTabularExplainer(\n",
    "    X_fraud_train_scaled,\n",
    "    feature_names=X_fraud.columns,\n",
    "    class_names=['Non-Fraud', 'Fraud'],\n",
    "    mode='classification',\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "print(\"LIME explainer created for fraud model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME explanation for individual predictions\n",
    "def explain_with_lime(explainer, model, instance, instance_idx, title):\n",
    "    \"\"\"Generate LIME explanation for a single instance\"\"\"\n",
    "    explanation = explainer.explain_instance(\n",
    "        instance, \n",
    "        model.predict_proba, \n",
    "        num_features=10\n",
    "    )\n",
    "    \n",
    "    # Plot explanation\n",
    "    fig = explanation.as_pyplot_figure()\n",
    "    fig.suptitle(f'LIME Explanation - {title} (Instance {instance_idx})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print explanation\n",
    "    print(f\"\\n{title} - Top feature contributions:\")\n",
    "    for feature, weight in explanation.as_list():\n",
    "        print(f\"  {feature}: {weight:.4f}\")\n",
    "    \n",
    "    return explanation\n",
    "\n",
    "# Explain fraud cases\n",
    "if len(fraud_indices) > 0:\n",
    "    fraud_instance_idx = fraud_indices[0]\n",
    "    fraud_instance = X_fraud_sample[fraud_instance_idx]\n",
    "    \n",
    "    fraud_explanation = explain_with_lime(\n",
    "        fraud_lime_explainer, fraud_model, fraud_instance, \n",
    "        fraud_instance_idx, \"Fraud Case\"\n",
    "    )\n",
    "\n",
    "# Explain non-fraud cases\n",
    "if len(non_fraud_indices) > 0:\n",
    "    non_fraud_instance_idx = non_fraud_indices[0]\n",
    "    non_fraud_instance = X_fraud_sample[non_fraud_instance_idx]\n",
    "    \n",
    "    non_fraud_explanation = explain_with_lime(\n",
    "        fraud_lime_explainer, fraud_model, non_fraud_instance, \n",
    "        non_fraud_instance_idx, \"Non-Fraud Case\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIME Analysis for Credit Card Model\n",
    "print(\"=== LIME ANALYSIS - CREDIT CARD MODEL ===\")\n",
    "\n",
    "# Create LIME explainer for credit card model\n",
    "credit_lime_explainer = LimeTabularExplainer(\n",
    "    X_credit_train_scaled,\n",
    "    feature_names=X_credit.columns,\n",
    "    class_names=['Non-Fraud', 'Fraud'],\n",
    "    mode='classification',\n",
    "    discretize_continuous=True\n",
    ")\n",
    "\n",
    "# Find fraud and non-fraud examples in credit data\n",
    "credit_fraud_indices = np.where(y_credit_sample == 1)[0]\n",
    "credit_non_fraud_indices = np.where(y_credit_sample == 0)[0]\n",
    "\n",
    "# Explain credit card fraud cases\n",
    "if len(credit_fraud_indices) > 0:\n",
    "    credit_fraud_idx = credit_fraud_indices[0]\n",
    "    credit_fraud_instance = X_credit_sample[credit_fraud_idx]\n",
    "    \n",
    "    credit_fraud_explanation = explain_with_lime(\n",
    "        credit_lime_explainer, credit_model, credit_fraud_instance, \n",
    "        credit_fraud_idx, \"Credit Card Fraud Case\"\n",
    "    )\n",
    "\n",
    "# Explain credit card non-fraud cases\n",
    "if len(credit_non_fraud_indices) > 0:\n",
    "    credit_non_fraud_idx = credit_non_fraud_indices[0]\n",
    "    credit_non_fraud_instance = X_credit_sample[credit_non_fraud_idx]\n",
    "    \n",
    "    credit_non_fraud_explanation = explain_with_lime(\n",
    "        credit_lime_explainer, credit_model, credit_non_fraud_instance, \n",
    "        credit_non_fraud_idx, \"Credit Card Non-Fraud Case\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comparison of SHAP vs LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SHAP and LIME explanations\n",
    "print(\"=== SHAP vs LIME COMPARISON ===\")\n",
    "\n",
    "def compare_explanations(shap_values, lime_explanation, feature_names, instance_idx, title):\n",
    "    \"\"\"Compare SHAP and LIME explanations for the same instance\"\"\"\n",
    "    \n",
    "    # Get SHAP values for the instance\n",
    "    shap_instance = shap_values[instance_idx]\n",
    "    \n",
    "    # Get LIME values\n",
    "    lime_dict = dict(lime_explanation.as_list())\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    comparison_data = []\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        shap_val = shap_instance[i]\n",
    "        lime_val = 0\n",
    "        \n",
    "        # Find corresponding LIME value\n",
    "        for lime_feature, lime_weight in lime_dict.items():\n",
    "            if feature in lime_feature or lime_feature in feature:\n",
    "                lime_val = lime_weight\n",
    "                break\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Feature': feature,\n",
    "            'SHAP': shap_val,\n",
    "            'LIME': lime_val\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # SHAP values\n",
    "    top_shap = comparison_df.nlargest(10, 'SHAP', keep='all')\n",
    "    ax1.barh(range(len(top_shap)), top_shap['SHAP'])\n",
    "    ax1.set_yticks(range(len(top_shap)))\n",
    "    ax1.set_yticklabels(top_shap['Feature'])\n",
    "    ax1.set_title(f'SHAP Values - {title}')\n",
    "    ax1.set_xlabel('SHAP Value')\n",
    "    \n",
    "    # LIME values\n",
    "    lime_data = [(k, v) for k, v in lime_dict.items()]\n",
    "    lime_features, lime_values = zip(*lime_data) if lime_data else ([], [])\n",
    "    \n",
    "    if lime_values:\n",
    "        ax2.barh(range(len(lime_values)), lime_values)\n",
    "        ax2.set_yticks(range(len(lime_values)))\n",
    "        ax2.set_yticklabels([f[:20] + '...' if len(f) > 20 else f for f in lime_features])\n",
    "        ax2.set_title(f'LIME Values - {title}')\n",
    "        ax2.set_xlabel('LIME Weight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Compare explanations for fraud case\n",
    "if len(fraud_indices) > 0 and 'fraud_explanation' in locals():\n",
    "    fraud_comparison = compare_explanations(\n",
    "        fraud_shap_values[1], fraud_explanation, X_fraud.columns, \n",
    "        fraud_indices[0], \"Fraud Case\"\n",
    "    )\n",
    "    print(\"\\nFraud Case - SHAP vs LIME Comparison:\")\n",
    "    print(fraud_comparison.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Global vs Local Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vs Local Explanations Analysis\n",
    "print(\"=== GLOBAL vs LOCAL EXPLANATIONS ===\")\n",
    "\n",
    "# Global explanation using SHAP (feature importance across all samples)\n",
    "global_importance = np.abs(fraud_shap_values[1]).mean(axis=0)\n",
    "global_df = pd.DataFrame({\n",
    "    'Feature': X_fraud.columns,\n",
    "    'Global_Importance': global_importance\n",
    "}).sort_values('Global_Importance', ascending=False)\n",
    "\n",
    "print(\"\\nGlobal Feature Importance (SHAP):\")\n",
    "print(global_df.head(10))\n",
    "\n",
    "# Local explanations for multiple instances\n",
    "print(\"\\nLocal Explanations for Different Instances:\")\n",
    "\n",
    "# Analyze local explanations for different types of cases\n",
    "local_explanations = []\n",
    "instance_types = []\n",
    "\n",
    "# Sample different instances\n",
    "sample_indices_analysis = np.random.choice(len(X_fraud_sample), min(5, len(X_fraud_sample)), replace=False)\n",
    "\n",
    "for idx in sample_indices_analysis:\n",
    "    instance_shap = fraud_shap_values[1][idx]\n",
    "    instance_type = \"Fraud\" if y_fraud_sample.iloc[idx] == 1 else \"Non-Fraud\"\n",
    "    \n",
    "    # Get top 3 features for this instance\n",
    "    top_indices = np.argsort(np.abs(instance_shap))[-3:]\n",
    "    top_features = [X_fraud.columns[i] for i in top_indices]\n",
    "    top_values = [instance_shap[i] for i in top_indices]\n",
    "    \n",
    "    local_explanations.append({\n",
    "        'Instance': idx,\n",
    "        'Type': instance_type,\n",
    "        'Top_Features': top_features,\n",
    "        'SHAP_Values': top_values\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nInstance {idx} ({instance_type}):\")\n",
    "    for feature, value in zip(top_features, top_values):\n",
    "        print(f\"  {feature}: {value:.4f}\")\n",
    "\n",
    "# Visualize global vs local importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Global importance\n",
    "plt.subplot(2, 1, 1)\n",
    "top_global = global_df.head(10)\n",
    "plt.barh(range(len(top_global)), top_global['Global_Importance'])\n",
    "plt.yticks(range(len(top_global)), top_global['Feature'])\n",
    "plt.title('Global Feature Importance (Average |SHAP| values)')\n",
    "plt.xlabel('Average Absolute SHAP Value')\n",
    "\n",
    "# Local importance variation\n",
    "plt.subplot(2, 1, 2)\n",
    "feature_std = np.std(np.abs(fraud_shap_values[1]), axis=0)\n",
    "std_df = pd.DataFrame({\n",
    "    'Feature': X_fraud.columns,\n",
    "    'Importance_Std': feature_std\n",
    "}).sort_values('Importance_Std', ascending=False)\n",
    "\n",
    "top_std = std_df.head(10)\n",
    "plt.barh(range(len(top_std)), top_std['Importance_Std'])\n",
    "plt.yticks(range(len(top_std)), top_std['Feature'])\n",
    "plt.title('Feature Importance Variation Across Instances (Std of |SHAP| values)')\n",
    "plt.xlabel('Standard Deviation of Absolute SHAP Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInsights:\")\n",
    "print(\"- Global importance shows which features are generally most important\")\n",
    "print(\"- High variation indicates features that are important for some instances but not others\")\n",
    "print(\"- Local explanations help understand individual predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Comparison Using Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different models using explainability\n",
    "print(\"=== MODEL COMPARISON USING EXPLAINABILITY ===\")\n",
    "\n",
    "# SHAP analysis for Logistic Regression\n",
    "fraud_lr_explainer = shap.LinearExplainer(fraud_lr, X_fraud_train_scaled)\n",
    "fraud_lr_shap_values = fraud_lr_explainer.shap_values(X_fraud_sample)\n",
    "\n",
    "# Compare feature importance between Random Forest and Logistic Regression\n",
    "rf_importance = np.abs(fraud_shap_values[1]).mean(axis=0)\n",
    "lr_importance = np.abs(fraud_lr_shap_values).mean(axis=0)\n",
    "\n",
    "comparison_models_df = pd.DataFrame({\n",
    "    'Feature': X_fraud.columns,\n",
    "    'Random_Forest': rf_importance,\n",
    "    'Logistic_Regression': lr_importance\n",
    "})\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Scatter plot of feature importance\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.scatter(comparison_models_df['Random_Forest'], comparison_models_df['Logistic_Regression'])\n",
    "plt.xlabel('Random Forest Importance')\n",
    "plt.ylabel('Logistic Regression Importance')\n",
    "plt.title('Feature Importance Comparison: Random Forest vs Logistic Regression')\n",
    "\n",
    "# Add feature labels for top features\n",
    "for i, feature in enumerate(comparison_models_df['Feature']):\n",
    "    if (comparison_models_df.iloc[i]['Random_Forest'] > 0.01 or \n",
    "        comparison_models_df.iloc[i]['Logistic_Regression'] > 0.01):\n",
    "        plt.annotate(feature, \n",
    "                    (comparison_models_df.iloc[i]['Random_Forest'], \n",
    "                     comparison_models_df.iloc[i]['Logistic_Regression']),\n",
    "                    fontsize=8, alpha=0.7)\n",
    "\n",
    "# Add diagonal line\n",
    "max_val = max(comparison_models_df['Random_Forest'].max(), \n",
    "              comparison_models_df['Logistic_Regression'].max())\n",
    "plt.plot([0, max_val], [0, max_val], 'r--', alpha=0.5)\n",
    "\n",
    "# Bar plot comparison for top features\n",
    "plt.subplot(2, 1, 2)\n",
    "top_features_combined = comparison_models_df.nlargest(8, 'Random_Forest')\n",
    "\n",
    "x = np.arange(len(top_features_combined))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, top_features_combined['Random_Forest'], width, \n",
    "        label='Random Forest', alpha=0.8)\n",
    "plt.bar(x + width/2, top_features_combined['Logistic_Regression'], width, \n",
    "        label='Logistic Regression', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('SHAP Importance')\n",
    "plt.title('Top Features Comparison: Random Forest vs Logistic Regression')\n",
    "plt.xticks(x, top_features_combined['Feature'], rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Features - Random Forest:\")\n",
    "print(comparison_models_df.nlargest(5, 'Random_Forest')[['Feature', 'Random_Forest']])\n",
    "\n",
    "print(\"\\nTop 5 Features - Logistic Regression:\")\n",
    "print(comparison_models_df.nlargest(5, 'Logistic_Regression')[['Feature', 'Logistic_Regression']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Actionable Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate actionable insights\n",
    "print(\"=== ACTIONABLE INSIGHTS AND RECOMMENDATIONS ===\")\n",
    "\n",
    "# Analyze feature patterns in fraud vs non-fraud cases\n",
    "fraud_cases_shap = fraud_shap_values[1][y_fraud_sample == 1]\n",
    "non_fraud_cases_shap = fraud_shap_values[1][y_fraud_sample == 0]\n",
    "\n",
    "if len(fraud_cases_shap) > 0 and len(non_fraud_cases_shap) > 0:\n",
    "    fraud_mean_shap = np.mean(fraud_cases_shap, axis=0)\n",
    "    non_fraud_mean_shap = np.mean(non_fraud_cases_shap, axis=0)\n",
    "    \n",
    "    # Features that distinguish fraud from non-fraud\n",
    "    difference = fraud_mean_shap - non_fraud_mean_shap\n",
    "    \n",
    "    distinguishing_features = pd.DataFrame({\n",
    "        'Feature': X_fraud.columns,\n",
    "        'Fraud_SHAP': fraud_mean_shap,\n",
    "        'Non_Fraud_SHAP': non_fraud_mean_shap,\n",
    "        'Difference': difference\n",
    "    }).sort_values('Difference', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"\\nFeatures that most distinguish Fraud from Non-Fraud:\")\n",
    "    print(distinguishing_features.head(10))\n",
    "    \n",
    "    # Visualize distinguishing features\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    top_distinguishing = distinguishing_features.head(8)\n",
    "    \n",
    "    x = np.arange(len(top_distinguishing))\n",
    "    width = 0.35\n",
    "    \n",
    "    plt.bar(x - width/2, top_distinguishing['Fraud_SHAP'], width, \n",
    "            label='Fraud Cases', alpha=0.8, color='red')\n",
    "    plt.bar(x + width/2, top_distinguishing['Non_Fraud_SHAP'], width, \n",
    "            label='Non-Fraud Cases', alpha=0.8, color='blue')\n",
    "    \n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Average SHAP Value')\n",
    "    plt.title('Average SHAP Values: Fraud vs Non-Fraud Cases')\n",
    "    plt.xticks(x, top_distinguishing['Feature'], rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate business recommendations\n",
    "print(\"\\n=== BUSINESS RECOMMENDATIONS ===\")\n",
    "print(\"\\n1. FEATURE MONITORING:\")\n",
    "top_3_features = fraud_importance_df.head(3)['feature'].tolist()\n",
    "for i, feature in enumerate(top_3_features, 1):\n",
    "    print(f\"   {i}. Monitor '{feature}' closely - highest predictive power for fraud\")\n",
    "\n",
    "print(\"\\n2. RISK SCORING:\")\n",
    "print(\"   - Implement real-time risk scoring based on top features\")\n",
    "print(\"   - Set thresholds for automatic flagging of suspicious transactions\")\n",
    "\n",
    "print(\"\\n3. MODEL INTERPRETATION:\")\n",
    "print(\"   - Use SHAP values for explaining individual fraud predictions to investigators\")\n",
    "print(\"   - LIME explanations can help in regulatory compliance and audit trails\")\n",
    "\n",
    "print(\"\\n4. FEATURE ENGINEERING:\")\n",
    "high_variation_features = std_df.head(3)['Feature'].tolist()\n",
    "print(f\"   - Features with high variation ({', '.join(high_variation_features)}) may benefit from\")\n",
    "print(\"     additional context or interaction terms\")\n",
    "\n",
    "print(\"\\n5. MODEL IMPROVEMENT:\")\n",
    "print(\"   - Random Forest and Logistic Regression show different feature importance patterns\")\n",
    "print(\"   - Consider ensemble methods to leverage both perspectives\")\n",
    "print(\"   - Focus data collection efforts on top distinguishing features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save explainability results\n",
    "print(\"=== SAVING EXPLAINABILITY RESULTS ===\")\n",
    "\n",
    "import os\n",
    "os.makedirs('../explainability_results', exist_ok=True)\n",
    "\n",
    "# Save feature importance results\n",
    "fraud_importance_df.to_csv('../explainability_results/fraud_feature_importance_shap.csv', index=False)\n",
    "credit_importance_df.to_csv('../explainability_results/credit_feature_importance_shap.csv', index=False)\n",
    "\n",
    "# Save model comparison results\n",
    "comparison_models_df.to_csv('../explainability_results/model_comparison_shap.csv', index=False)\n",
    "\n",
    "# Save distinguishing features\n",
    "if 'distinguishing_features' in locals():\n",
    "    distinguishing_features.to_csv('../explainability_results/fraud_distinguishing_features.csv', index=False)\n",
    "\n",
    "# Save SHAP values for future use\n",
    "np.save('../explainability_results/fraud_shap_values.npy', fraud_shap_values[1])\n",
    "np.save('../explainability_results/credit_shap_values.npy', credit_shap_values[1])\n",
    "\n",
    "print(\"Explainability results saved successfully!\")\n",
    "print(\"\\nFiles saved:\")\n",
    "print(\"- fraud_feature_importance_shap.csv\")\n",
    "print(\"- credit_feature_importance_shap.csv\")\n",
    "print(\"- model_comparison_shap.csv\")\n",
    "print(\"- fraud_distinguishing_features.csv\")\n",
    "print(\"- SHAP values arrays (.npy files)\")\n",
    "\n",
    "print(\"\\n=== TASK 3 COMPLETED SUCCESSFULLY ===\")\n",
    "print(\"All model explainability steps have been completed:\")\n",
    "print(\"✅ SHAP analysis for both fraud and credit card models\")\n",
    "print(\"✅ LIME analysis for individual prediction explanations\")\n",
    "print(\"✅ Global vs local explainability comparison\")\n",
    "print(\"✅ Model comparison using explainability metrics\")\n",
    "print(\"✅ Actionable business insights generated\")\n",
    "print(\"✅ Explainability results saved for deployment\")\n",
    "print(\"\\nReady for Task 4: Model Deployment and API Development!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}